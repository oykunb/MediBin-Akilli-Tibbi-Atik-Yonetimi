{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d578d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7805efa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri seti başarıyla kaydedildi: atik.npz\n",
      "Alt sınıf adları kaydedildi: subclass_names.npy\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_save_dataset(dataset_path, save_path, max_files_per_class=350, test_size=0.2):\n",
    "    classes = os.listdir(dataset_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    subclass_names = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "\n",
    "        if os.path.isdir(class_path):\n",
    "            for subclass_name in os.listdir(class_path):\n",
    "                subclass_path = os.path.join(class_path, subclass_name)\n",
    "\n",
    "                if os.path.isdir(subclass_path):\n",
    "                    subclass_names.append(subclass_name)\n",
    "\n",
    "                    count = 0\n",
    "                    for image_name in os.listdir(subclass_path):\n",
    "                        if count >= max_files_per_class:\n",
    "                            break\n",
    "\n",
    "                        image_path = os.path.join(subclass_path, image_name)\n",
    "                        image = cv2.imread(image_path)\n",
    "                        if image is not None:\n",
    "                            image = cv2.resize(image, (128, 128))\n",
    "                            images.append(image)\n",
    "                            labels.append(i)\n",
    "                            count += 1\n",
    "\n",
    "    images = np.array(images, dtype=np.float32) / 255.0\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    np.savez(save_path, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
    "    print(f\"Veri seti başarıyla kaydedildi: {save_path}\")\n",
    "\n",
    "    subclass_names_path = \"subclass_names.npy\"\n",
    "    np.save(subclass_names_path, subclass_names)\n",
    "    print(f\"Alt sınıf adları kaydedildi: {subclass_names_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "daa7728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"atiklar\"\n",
    "save_path = \"atik.npz\"\n",
    "preprocess_and_save_dataset(dataset_path, save_path, max_files_per_class=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3412b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('atik.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69db6a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 18s 493ms/step - loss: 1.1323 - accuracy: 0.5004 - val_loss: 0.9932 - val_accuracy: 0.4857\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 18s 502ms/step - loss: 0.9030 - accuracy: 0.5670 - val_loss: 0.9301 - val_accuracy: 0.5518\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 18s 523ms/step - loss: 0.8743 - accuracy: 0.5705 - val_loss: 0.8784 - val_accuracy: 0.5911\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 18s 510ms/step - loss: 0.8351 - accuracy: 0.6009 - val_loss: 0.8553 - val_accuracy: 0.6107\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 18s 506ms/step - loss: 0.7795 - accuracy: 0.6482 - val_loss: 0.8670 - val_accuracy: 0.6179\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 19s 533ms/step - loss: 0.7005 - accuracy: 0.6799 - val_loss: 0.8777 - val_accuracy: 0.6179\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 18s 512ms/step - loss: 0.6386 - accuracy: 0.7254 - val_loss: 0.9106 - val_accuracy: 0.6054\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 19s 533ms/step - loss: 0.5352 - accuracy: 0.7728 - val_loss: 0.9436 - val_accuracy: 0.6339\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 18s 504ms/step - loss: 0.4690 - accuracy: 0.8054 - val_loss: 1.1223 - val_accuracy: 0.5732\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 20s 563ms/step - loss: 0.3862 - accuracy: 0.8469 - val_loss: 1.1946 - val_accuracy: 0.6321\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 19s 532ms/step - loss: 0.3192 - accuracy: 0.8728 - val_loss: 1.3171 - val_accuracy: 0.6143\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 20s 580ms/step - loss: 0.2948 - accuracy: 0.8844 - val_loss: 1.3503 - val_accuracy: 0.6179\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 19s 552ms/step - loss: 0.2218 - accuracy: 0.9192 - val_loss: 1.7092 - val_accuracy: 0.6375\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 18s 512ms/step - loss: 0.1728 - accuracy: 0.9371 - val_loss: 1.7363 - val_accuracy: 0.5804\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 18s 526ms/step - loss: 0.1499 - accuracy: 0.9460 - val_loss: 1.8548 - val_accuracy: 0.6125\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 18s 523ms/step - loss: 0.1306 - accuracy: 0.9522 - val_loss: 2.1209 - val_accuracy: 0.6357\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 18s 518ms/step - loss: 0.1322 - accuracy: 0.9567 - val_loss: 2.2607 - val_accuracy: 0.6018\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 18s 516ms/step - loss: 0.0882 - accuracy: 0.9723 - val_loss: 2.4318 - val_accuracy: 0.5946\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 19s 537ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 2.8079 - val_accuracy: 0.6054\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 20s 574ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 3.1273 - val_accuracy: 0.6125\n",
      "18/18 [==============================] - 1s 69ms/step - loss: 3.1273 - accuracy: 0.6125\n",
      "Test accuracy: 0.612500011920929\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = data['x_train'], data['y_train'], data['x_test'], data['y_test']\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20,batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbe820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"ornek.jpg\"\n",
    "test_image = cv2.imread(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7820633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen alt sınıf: cam\n"
     ]
    }
   ],
   "source": [
    "if test_image is not None:\n",
    "    test_image = cv2.resize(test_image, (128, 128))\n",
    "    test_image = np.expand_dims(test_image, axis=0) / 255.0\n",
    "    \n",
    "    predictions = model.predict(test_image)\n",
    "    predicted_subclass_index = np.argmax(predictions)\n",
    "\n",
    "    subclass_names_path = \"subclass_names.npy\"\n",
    "    subclass_names = np.load(subclass_names_path)\n",
    "    \n",
    "    predicted_subclass_name = subclass_names[predicted_subclass_index]\n",
    "    print(f\"Tahmin edilen alt sınıf: {predicted_subclass_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
